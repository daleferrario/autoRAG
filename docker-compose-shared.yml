services:
  chromadb:
    image: chromadb/chroma
    environment:
      - IS_PERSISTENT=TRUE
    container_name: chromadb
    ports:
      - "8000:8000"
    volumes:
      - chroma_volume:/chroma/chroma
    networks:
      - distill_network
    restart: always

  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_volume:/root/.ollama
    networks:
      - distill_network
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
  
  ollama_model_puller:
      image: curlimages/curl:latest
      container_name: ollama_model_puller
      command: >
        sh -c "
          while ! curl -s http://ollama:11434/api/list > /dev/null; do
            echo 'Waiting for ollama server...'
            sleep 1
          done &&
          curl -X POST http://ollama:11434/api/pull -H 'Content-Type: application/json' -d '{\"name\": \"llama3\"}' &&
          curl -X POST http://ollama:11434/api/pull -H 'Content-Type: application/json' -d '{\"name\": \"mxbai-embed-large\"}'"
      restart: "no"
      networks:
        - distill_network
      depends_on:
        - ollama

  discord_bot:
    image: ajferrario/distill-discord-bot
    environment:
      REST_SERVER_PORT: 8001
      DISCORD_BOT_KEY: ${DISCORD_BOT_KEY}
    container_name: discord_bot
    networks:
      - distill_network
    restart: always
  
  slack_app:
    image: ajferrario/distill-slack-app
    environment:
      REST_SERVER_PORT: 8001
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN}
      SLACK_APP_TOKEN: ${SLACK_APP_TOKEN}
    container_name: slack_app
    networks:
      - distill_network
    restart: always

networks:
  distill_network:
    name: distill_network
    driver: bridge

volumes:
  chroma_volume:
  ollama_volume:
